PASTE YOUR BHASHINI HTML/TEXT CONTENT HERE
(Include API Keys, User ID, and Endpoint URLs)
bhashini details 
User ID : 481d81f3bbfc4bab880b7189394ffc1b

App Name : beej

Udyat Key :  48624f10dd-646d-45c3-acf8-3b686173aa5c

Inference Api key: 4YuCVKJP_1EAY55nly2vlXxZlgXnZbqDIs0dCnrUlGIECeOh1hSlqlPUq1btSPl5

Data tracking is on 

this things i have in my api key repo


Overall Understanding of the API Calls
This page will help the integrator understand the number of calls that are to be made to do any specific number of tasks that may or may not include Speech Recognition, Translation and Text to Speech.

This Bhashini Documentation has been written by Bhashini Team. Please reach out to Bhashini Team on email id (digitalindiabhashinidivision@gmail.com), if you face issues implementing the APIs.

Please refer to Appendix for details on full forms.

What models are available on ULCA?
Our Research and Development groups which comprises of different renowned institutes of India like IIT(s), IIIT(s), CDAC etc. have developed models which can do Speech Recognition, Translations, Text to Speech, Optical Character Recognition and many more for Indian languages. Our ULCA Platform exposes these AI/ML models (each identified with an unique Model ID) and a try out page through which integrators can try these models.

Logo
ULCA
bhashini.gov.in
ULCA Repository of Models
Multiple models could be available that may have similar functionality. For ex. To do Speech Recognition of Hindi language, there may be multiple models available from different institute each uniquely identified by a model ID.

What is a ULCA pipeline?
ULCA Pipeline is a set of tasks that any specific pipeline supports. For example, any specific pipeline (identified by unique pipeline ID) can support the following:

What is Pipeline ID?


Another pipeline P2, may support only following Tasks and Task Sequences:
[NMT]
[TTS]
[NMT+TTS]

When to use which Pipeline ID?
Consider Bhashini provides a few pipelines (pipeline ID: P1, P2, etc.) that supports some Tasks and Task Sequences.

Case 1:
If the use case is to do only Translation where an integrator wants to translate a given sentence from one language to another in their app/project. For this use case, a pipeline which supports [NMT] shall be used. Since pipeline P1 and P2 both supports [NMT] task, either P1 or P2 can be used.

Case 2:
Consider another use case, where integrator would also want its users to be able to hear the output along with reading which would require both NMT and TTS to be done on the input text, integrator will need a pipeline that supports [NMT+TTS]. Since pipeline P1 and P2 both supports [NMT+TTS], either P1 or P2 can be used.

Case 3:
Consider yet another use case, where integrator wants to take the input in the form of voice and provide a translated text from one language to another. Integrator will, in this case, needs a pipeline which supports [ASR+NMT]. Since only Pipeline P1 supports ASR and NMT together, only P1 can be used.

Case 4:
Consider yet another use case, where the integrator wants to utilize ASR from Pipeline P1 and [NMT] from Pipeline P2. The integrator can achieve this as long as both pipelines point to the same API endpoint and are accessible with the same Authorization Keys.

Now, from Case 1 and 2, question arises, which one to use, since both are able to do the required task?
Integrators will have a detailed description of the capabilities of the pipeline, the models used in those pipelines, domains to which this pipeline may cater well. e.g. Certain pipelines are made for Medical Domain compared to some other pipeline which may cater to Agriculture domain better.
Along with description, there is a Search Pipeline API call as well which provides similar information for automation purposes.
Based on the understanding obtained from the portal as well as information obtained from the API, the integrator shall be able to determine which pipeline ID to use if multiple pipelines are available which does the same Tasks/Task Sequences.

Each of these pipelines are uniquely identified by Pipeline ID.

Each pipeline can support multiple and/or combination of tasks.

In each of the Task Sequences, order/sequence of tasks is important. e.g. If a pipeline supports [ASR+NMT+TTS], it will mean that on the input received, first speech recognition will be done, then it will be translated to another language following which Speech in the target language will be generated.

Flow of API calls
Integrator shall do following calls to get the output.

Pipeline Search API Call [Optional] 
Pipeline Search API Call helps the integrator to search for pipelines that are available to do specific Tasks or Task Sequences and can be used to filter pipeline search based on different parameters.

Integrators will be able to obtain Pipeline IDs required for their project using this call.  

Pipeline Config Call [Mandatory]
Once the integrator obtains the Pipeline ID either via Search Call or ULCA web portal, Pipeline Config call shall be sent to Bhashini along with the specific Task/Task Sequence that integrator want to do using this pipeline. Integrator should make sure that the sequence they are sending shall be supported by this pipeline.
There are additional configuration parameters which integrators may or may not send to further filter the response of this config call.

Pipeline Compute Call [Mandatory]
Pipeline Compute Call is the final call that will help the integrator to obtain the output of the pipeline task sent.

Language Codes
Throughout the APIs, Integrators will see that languages are referred by their language codes. For ex. Language Code for Hindi is hi, English is en, and so on.

Bhashini follows ISO-639 series of language codes.

Usage of these APIs shall be for the purposes of PoC only. If the Bhashini Sahyogi, Bhashini App Mitra or Bhashini Udyat Mitra wants to use the same on production systems or integrators are charging end-users, please reach out to Bhashini team for the paid version of the APIs and exploring Pricing Plans.

Available Models for usage
This page provides the integrator with details about the models available for usage within Bhashini and the Service ID's to be utilized for the languages accordingly.

The list below consists of Service ID's to be utilized, each Service ID helps connect with a specific model via the REST APIs of Bhashini. The Service ID's, task type supported by it (such as ASR, Translation, TTS, etc) and the languages supported by it are listed below.

ASR
Sl. No
Service ID
Language(s) Supported
Model Provider
1

bhashini/iitm/asr-dravidian--gpu--t4

Telugu, Kannada, Malayalam, Tamil

IIT Madras

2

ai4bharat/conformer-hi-gpu--t4

Hindi

AI4Bharat

3

ai4bharat/conformer-multilingual-dravidian-gpu--t4

Kannada, Malayalam, Tamil, Telugu

AI4Bharat

4

ai4bharat/conformer-multilingual-indo_aryan-gpu--t4

Hindi, Bengali, Marathi, Urdu, Odia, Punjabi, Gujarati, Sanskrit

AI4Bharat

5

ai4bharat/whisper-medium-en--gpu--t4

English

AI4Bharat

6

bhashini/ai4bharat/conformer-multilingual-asr

Assamese, Bengali, Bodo, Dogri, Gujarati, Hindi, Kannada, Kashmir, Goan Konkani, Maithili, Malayalam, Manipuri, Marathi, Nepali, Odia, Punjabi, Sanskrit, Santali, Sindhi, Tamil, Telugu, Urdu

AI4Bharat

7

bhashini/iitm/asr-indoaryan--gpu--t4

Gujarati, Odia, Hindi, Marathi, Punjabi, Bengali

IIT Madras

8

bhashini/iitm/asr-misc--gpu--t4

Bhojpuri, Urdu

IIT Madras

9

bhashini/iisc/asr-mai-t4

Maithili

IISC

10

bhashini/iisc/asr-bho-t4

Bhojpuri

IISC

Translation
Sl. No
Service ID
Source Language(s) Supported
Target Language(s) Supported
Model Provider
1

bhashini/iiith/nmt-all

Hindi, English, Assamese, Awadhi, Bengali, Bhojpuri, Braj, Bodo, Dogri, Konkani, Gondi, Gujarati, Hinglish, Ho, Kannada, Kashmiri, Khasi, Mizo, Maithili, Magahi, Malayalam, Marathi, Manipuri, Nepali, Oriya, Punjabi, Sanskrit, Santali, Sinhala, Sindhi, Tamil, Tulu, Telugu, Urdu, Kangri, Kashmiri

Hindi, English, Assamese, Awadhi, Bengali, Bhojpuri, Braj, Bodo, Dogri, Konkani, Gondi, Gujarati, Hinglish, Ho, Kannada, Kashmiri, Khasi, Mizo, Maithili, Magahi, Malayalam, Marathi, Manipuri, Nepali, Oriya, Punjabi, Sanskrit, Santali, Sinhala, Sindhi, Tamil, Tulu, Telugu, Urdu, Kangri, Kashmiri

IIIT Hyderabad

2

ai4bharat/indictrans-v2-all-gpu--t4

English, Goan Konkani, Gujarati, Sanskrit, Telugu, Marathi, Hindi, Odia, Manipuri,  Malayalam, Assamese, Dogri, Santali, Tamil, Sindhi, Bengali, Kashmiri, Kannada, Nepali

English, Goan Konkani, Gujarati, Sanskrit, Telugu, Marathi, Hindi, Odia, Manipuri, Malayalam, Assamese, Dogri, Santali, Tamil, Sindhi, Bengali, Kashmiri, Kannada, Nepali

AI4Bharat

3

Bhashini/IIITH/Trans/V1

Hindi, English, Telugu, Odia, Gujarati, Urdu,

Punjabi, Hindi, English, Telugu, Urdu, Gujarati, Odia, Sindhi, Dogri, Kashmiri

IIIT Hyderabad

4

iitb/trilingual-en_hi_mr-v1-gpu--t4

English, Assamese, Marathi, Hindi

Assamese, Hindi, Bodo, Nepali, English, Marathi, Maithili, Goan Konkani

IIT Bombay

5

bhashini/aukbc/disco-nmt

Malayalam, Hindi, Tamil

Malayalam, Hindi, Tamil

AUKBC

6

bhashini/cdac-noida/nmt

English, Hindi, Tamil, Odia , Bengali

English, Hindi, Tamil, Odia , Bengali

CDAC-Noida

7

bhashini/cdac-pune/nmt

English, Kannada, Gujarati,Malayalam

English, Kannada, Gujarati, Malayalam

CDAC-Pune

8

bhashini/ai4bharat/indictrans-v3

Assamese, Bengali, English, Gujarati, Hindi, Kannada, Malayalam, Marathi, Nepali, Odia, Punjabi, Sanskrit, Tamil, Telugu, Urdu

Assamese, Bengali, English, Gujarati, Hindi, Kannada, Malayalam, Marathi, Nepali, Odia, Punjabi, Sanskrit, Tamil, Telugu, Urdu

AI4Bharat

9

bhashini/iitkhg/nmt

Hindi

Sanskrit

IIT Kharagpur

Transliteration
Sl. No
Service ID
Source Language(s) Supported
Target Language(s) Supported
Model Provider
1

ai4bharat/indicxlit--cpu-fsv2

English, Goan Konkani, Gujarati, Sanskrit, Telugu, Marathi, Hindi, Odia, Manipuri, Malayalam, Assamese, Dogri, Santali, Tamil, Sindhi, Bengali, Kashmiri, Kannada, Nepali, Punjabi, Maithili,  Urdu, Sinhala, Bodo,

English, Goan Konkani, Gujarati, Sanskrit, Telugu, Marathi, Hindi, Odia, Manipuri, Malayalam, Assamese, Dogri, Santali, Tamil, Sindhi, Bengali, Kashmiri, Kannada, Nepali, Punjabi, Maithili, Urdu, Sinhala,  Bodo

AI4Bharat

TTS
Sl. No
Service ID
Language(s) Supported
Model Provider
1

Bhashini/IITM/TTS

Assamese, Bengali, Bodo, Dogri, English, Gujarati, Hindi, Kannada, Goan Konkani, Maithili, Malayalam, Manipuri, Marathi, Nepali, Odia, Punjabi, Rajasthani, Sanskrit, Tamil, Telugu, Urdu

IIT Madras

2

ai4bharat/indic-tts-coqui-dravidian-gpu--t4

Malayalam, Kannada, Tamil, Telugu

AI4Bharat

3

ai4bharat/indic-tts-coqui-indo_aryan-gpu--t4

Hindi, Marathi, Assamese, Bengali, Gujarat, Odia, Rajasthani, Punjabi

AI4Bharat

4

ai4bharat/indic-tts-coqui-misc-gpu--t4

English, Manipuri, Bodo

AI4Bharat

5

Bhashini/IISC/TTS

Kannada, Telugu, English, Hindi, Marathi, Bengali, Gujarati, Maithili, Bhojpuri, Chhattisgarhi, Magahi

IISC (SYSPIN)

Audio Language Detection
Sl. No
Service ID
Language(s) Supported
Model Provider
1

bhashini/iitmandi/audio-lang-detection/gpu

Assamese, Bengali, English, Hindi, Kannada, Gujarati, Malayalam, Marathi, Odia, Punjabi, Tamil, Telugu

IIT Mandi

Text Language Detection
Sl. No
Service ID
Language(s) Supported
Model Provider
1

bhashini/indic-lang-detection-all

Assamese, Bengali, Bodo, Dogri, English, Gujarati, Hindi, Kannada, Kashmiri, Konkani, Maithili, Malayalam, Manipuri, Marathi, Nepali, Oriya, Punjabi, Sanskrit, Santali, Sindhi, Tamil, Telugu, Urdu

AI4Bharat

2

bhashini/iiiith/indic-lang-detection-all

Assamese, Bengali, English, Gujarati, Hindi, Kannada, Malayalam, Manipuri, Marathi, Oriya, Punjabi, Tamil, Telugu, Urdu

IIIT Hyderabad

3

bhashini/indic/tld

Assamese(bng script), Bodo, Bangla, Dogri, English, Gujarati, Hindi, Kannada, Kashmiri, Konkani, Maithili, Malayalam, Manipuri, Marathi, Nepali, Odia, Punjabi, Sanskrit, Santali, Sindhi, Tamil, Telugu, Urdu

-

Named Entity Recognition
Sl. No
Service ID
Language(s) Supported
Model Provider
1

bhashini/iiith/ner

Hindi, Urdu, Odia, Telugu

IIIT Hyderabad

2

bhashini/ai4bharat/indic-ner

Assamese, Bengali, Gujarati, Hindi, Kannada, Malayalam, Telugu, Marathi, Oriya, Punjabi, Tamil

AI4Bharat

3

bhashini/aukbc/ner

Hindi, Bengali, Marathi, Punjabi

AUKBC

OCR
Sl. No
Service ID
Language(s) Supported
Modality
Model Provider
1

bhashini/iiith-ocr-sceneText-all

Assamese, Bengali, Gujarati, Hindi, Kannada, Malayalam, Manipuri, Marathi, Oriya, Punjabi, Tamil, Telugu, Urdu

Scene Text

IIIT Hyderabad

2

bhashini/iiith/ocr-hw-bhaasha

Bengali, Hindi, Malayalam, Marathi, Punjabi, Telugu, Kannada, Tamil

Handwritten

IIIT Hyderabad

3

bhashini/iiith-bhasha-ocr

Assamese, Bengali, Bodo, Dogri, English, Gujarati, Hindi, Kannada, Kashmiri, Konkani, Maithali, Nepali, Malayalam, Manipuri, Marathi, Oriya, Punjabi, Sanskrit, Santali, Sindhi, Tamil, Telugu

Printed Text

IIIT Hyderabad

Speaker Enrollment & Verification
SI.No
Service ID
Language(s) Supported
Model Provider
1

bhashini/iitdharwad/speaker-enrollment

 All Languages

IIT Dharwad 

2

bhashini/iitdharwad/speaker-verification

All Languages

IIT Dharwad

Speaker Diarization
SI.No
Service ID
Language(s) Supported
Model Provider
1

bhashini/iisc/speaker-diarization

All Languages

IISC

2

bhashini/speaker-diarization

All Languages

Open Source

Language Diarization
S.No
Service ID
Language(s) Supported
Model Provider
1

bhashini/nitk/language-diarization

All Languages

NITK

Voice Cloning
S.No
Service ID
Language(s) Supported
Model Provider
1

bhashini/ai4b/indicf5-tts

Assamese, Bengali, Gujarati, Hindi, Kannada, Malayalam, Marathi, Odia, Punjabi, Tamil, Telugu.

AI4Bharat

Lip Sync
S.No
Service ID
Language(s) Supported
Model Provider
1

bhashini/iitm/lip-sync

All Languages

IIT Madras

KWS (Key-Word Spotting)
S.No
Service ID
Language(s) Supported
Model Provider
1

bhashini/iitg/kws

Bengali, Manipuri, Mizo

IIT Guwahati

Pipeline Search Call
This page will help the integrator to understand the Pipeline Search API Call. This page will detail out the API call, its parameters, understanding of the Input and Output Payloads.

Currently, 4 pipeline IDs are available to used directly as follows:

IIT Madras Models: 660fa5bec7fb5b0328229016 [ASR and TTS task types are available in config call for now]

IIT Bombay Models: 660f813c0413087224435d2c [Translation task type are available in config call for now]

IIIT Hyderabad Models: 660f866443e53d4133f65317 [Translation task type are available in config call for now]

Initial Pipeline Models: 64392f96daac500b55c543cd [ASR, Translation, Transliteration and TTS task types are available in config call for now]

Pipeline Config Call
This page will help the integrator to get the details of each pipeline based on Pipeline ID. This page will detail out the API call, its parameters, understanding of the Input and Output Payloads.

Endpoint: https://meity-auth.ulcacontrib.org/ulca/apis/v0/model/getModelsPipeline

Additional Headers:

userID

ulcaApiKey

Payload:

Tab 1: JSON payload without any configuration parameters

Tab 2: JSON payload with some configuration parameters

Additional Headers
Below is the understanding and process of obtaining the additional Headers that shall be sent to make the Pipeline Config API Call. These headers are used for uniquely identifying each integrator for a particular application and authenticate them for the API usage.

userID: Uniquely identify the Integrator.
ulcaApiKey: to Authenticate this particular userID

Below is a screenshot from the Postman. Along with standard headers that are sent automatically, userID and ulcaApiKey are the additional parameters sent.


Postman screenshot of additional parameters
Both userID and ulcaApiKey can be obtained from the My Profile section after logging in.
Request Payload
This sub-page helps the integrator to understand two different types of request payload, one without any additional configuration parameters, and one with additional configuration parameters.

Without configuration parameters
With Configuration Parameters

Copy
{
    "pipelineTasks": [
        {
            "taskType": "asr",
            "config": {
                "language": {
                    "sourceLanguage": "xx"
                }
            }
        },
        {
            "taskType": "translation",
            "config": {
                "language": {
                    "sourceLanguage": "xx",
                    "targetLanguage": "yy"
                }
            }
        },
        {
            "taskType": "tts",
            "config": {
                "language": {
                    "sourceLanguage": "yy"
                }
            }
        },
        
    ],
    "pipelineRequestConfig": {
        "pipelineId" : "xxxx8d51ae52cxxxxxxxx"
    }
}
Parameters
Only additional parameter config is detailed out below. Rest of the parameters' understanding remains the same as Without configuration parameters.

config
Type: dictionary

config parameter is used for sending configuration parameters to the server for each taskType. Each taskType may have some common parameters such as language and some parameters which are specific to each taskType.

Currently, there are no additional taskType specific parameters. Once added, they will be described here.

config
ASR
Translation
TTS
Type: dictionary

contains:

language
Type: dictionary

contains:

sourceLanguage
Type: String

Source Language will take the ISO-639 code of the language as the input. This parameter will tell the server that integrator wants to receive the information and details about Speech Recognition in this specific language.

Response Payload
This sub-page helps the integrator to understand two different types of response payload, based on different request payload.

Request sent without configuration parameter
Request sent with Configuration Parameter
Complete Payload

Copy
{
    "languages": [
        {
            "sourceLanguage": "gu",
            "targetLanguageList": [
                "bn"
            ]
        }
    ],
    "pipelineResponseConfig": [
        {
            "taskType": "asr",
            "config": [
                {
                    "serviceId": "ai4bharat/conformer-multilingual-indo_aryan-gpu--t4",
                    "modelId": "6411746056e9de23f65b5425",
                    "language": {
                        "sourceLanguage": "gu"
                    },
                    "domain": [
                        "general"
                    ]
                }
            ]
        },
        {
            "taskType": "translation",
            "config": [
                {
                    "serviceId": "ai4bharat/indictrans-fairseq-i2i-gpu--t4",
                    "modelId": "62023eeb3fc51c3fe32b8c5b",
                    "language": {
                        "sourceLanguage": "gu",
                        "targetLanguage": "bn"
                    }
                }
            ]
        },
        {
            "taskType": "tts",
            "config": [
                {
                    "serviceId": "ai4bharat/indic-tts-coqui-indo_aryan-gpu--t4",
                    "modelId": "636e60e586369150cb00432a",
                    "language": {
                        "sourceLanguage": "bn"
                    },
                    "supportedVoices": [
                        "male",
                        "female"
                    ]
                }
            ]
        }
    ],
    "pipelineInferenceAPIEndPoint": {
        "callbackUrl": "https://dhruva-api.bhashini.gov.in/services/inference/pipeline",
        "inferenceApiKey": {
            "name": "Authorization",
            "value": "m-LTAzxQVp6jjznmSR5RgKM"
        },
        "isMultilingualEnabled": true,
        "isSyncApi": true
    }
}
Complete Payload shows the JSON structure of the content that is received when Integrator makes a ULCA Config Call with some configuration details as detailed in Tab 2 of Request Payload. Here, the integrator has requested to do a combination of tasks ASR, Translation and TTS in that sequence from Gujarati to Bengali

Parameter: languages
The understanding of the parameters remains same as in previous tab.
Since the languages were already known to the integrator before-hand, therefore, the response contains configuration details for those languages only.

There may occur a possibility that Integrator wants to do any individual task or combination of tasks in a sequence for the languages that are not supported by that pipeline ID in which case the following response will be obtained:

Response Code: 400 Bad Request
Response Body:


Copy
{
    "code": "400 BAD_REQUEST",
    "message": "Sequence of languages not supported",
    "timestamp": "2023-04-14T06:32:12.133+00:00"
}
In such cases, it is recommended to send Pipeline Config Request without Configuration as shown in Tab 1 under Request Payload
Using which Integrators will know what all languages are supported by that pipeline ID.

Parameter: pipelineResponseConfig
The understanding of the parameters remains same as in previous tab.
Since the languages were already known to the integrator before-hand, therefore, the response contains configuration details for those languages only.

Parameter: pipelineInferenceAPIEndPoint
The understanding of the parameters remains same as in previous tab.

Pipeline Compute Call
This page will help the integrator to get the output of the task sequence requested. This page will detail out the API call, its parameters, understanding of the Input and Output Payloads.

Endpoint: Endpoint is obtained from the callbackURL parameter under pipelineInferenceAPIEnfPoint parameter from the Response Payload of Pipeline Config Call as shown here.

Additional Headers:
auth parameter key
auth parameter value

Payload:

ASR

Translation

TTS

ASR+Translation

Translation+TTS

ASR+Translation+TTS

Additional Headers
Below is the understanding and process of obtaining the additional Headers that shall be sent to make the Pipeline Compute API Call. These headers are used for uniquely identifying each integrator for a particular application and authenticate them for the API usage.

auth parameter key: This value is obtained from name parameter under inferenceApiKey under pipelineInferenceAPIEnfPoint. 

auth parameter value: This value is obtained from value parameter under inferenceApiKey under pipelineInferenceAPIEnfPoint. 

Request Payload
This sub-page helps the integrator to understand various different types of request payload based on the individual task or combination of tasks in that sequence that integrator wants to do.

Request Payload for Individual Task
ASR
Translation
TTS

Copy
{
    "pipelineTasks": [
        {
            "taskType": "asr",
            "config": {
                "language": {
                    "sourceLanguage": "xx"
                },
                "serviceId": "xxxxx--ssssss-d-ddd--dddd",
                "audioFormat": "wav",
                "samplingRate": 16000,
                "preProcessors": [
                    "vad"
                ],
                "postProcessors": [
                    "itn"
                ]
            }
        }
    ],
    "inputData": {
        "input": [
            {
                "source": null
            }
        ],
        "audio": [
            {
                "audioContent": "{{generated_base64_content}}"
            }
        ]
    }
}
This response contains 2 major parameters listed below and detailed further down the section:

pipelineTasks

inputData

Parameter: pipelineTasks
Type: Array

This parameter takes an array of tasks, in the form of dictionary of taskType and config, that are to be done by the integrator. 
In the above example, pipelineTasks takes only one dictionary (line 3-13) because integrator wants to do only ASR.

taskType parameter takes String that takes the value asr

config parameter takes a Dictionary that contains following parameters:

Language
Service ID
Audio Format
Sampling Rate
For ASR, language parameter only takes sourceLanguage which accepts ISO-639 Series Code of the language.

Parameters other than taskType, serviceId and config are optional.

Parameter: inputData
inputData Parameter takes the actual input from the integrator on which the individual task has to be done. It can take the input either via input parameter or audio parameter depending on the task to be done.
Since ASR is done on audio input data, for ASR, 

input parameter is optional, of no use for ASR but

audio parameter is mandatory.

audio parameter takes audioContent parameter which accepts base64 String of the actual audio captured. 

If audioFormat or/and samplingRate parameter is/are sent, integrator should make sure that these values correspond to the actual recorded audio.

Request Payload for Combination of Tasks in specific sequence
ASR+Translation
Translation+TTS
ASR+Translation+TTS

Copy
{
    "pipelineTasks": [
        {
            "taskType": "asr",
            "config": {
                "language": {
                    "sourceLanguage": "xx"
                },
                "serviceId": "xxxxx--ssssss-d-ddd--dddd",
                "audioFormat": "flac",
                "samplingRate": 16000
            }
        },
        {
            "taskType": "translation",
            "config": {
                "language": {
                    "sourceLanguage": "xx",
                    "targetLanguage": "yy"
                },
                "serviceId": "xxxxx--ssssss-d-ddd--mfkds"
            }
        }
    ],
    "inputData": {
        "input": [
            {
                "source": null
            }
        ],
        "audio": [
            {
                "audioContent": "{{generated_base64_content}}"
            }
        ]
    }
}
Parameter: pipelineTasks
Type: Array

This parameter takes an array of tasks, in the form of dictionary of taskType and config, that are to be done by the integrator. 
In the above example, pipelineTasks takes two dictionaries:

Line 3 to 13 i.e., ASR Dictionary

Line 14 to 23 i.e., Translation Dictionary

because integrator wants to do ASR of the input voice followed by Translation of the digital text. 

Line Number 7 and Line Number 18 are connected with below understanding. Consider a use-case described below:

Integrator wants to speak in say Hindi language and wants to see the translated output in Marathi. For this to happen, integrator has to:

Convert the Audio integrator has spoken to digital text i.e., ASR of Hindi

Translate this digital Hindi text to Marathi digital text i.e., Translation from Hindi to Marathi

Therefore, the language code for ASR that is to be inserted in Line 7, shall be hi, i.e., ISO 639 series code for Hindi. Once this Hindi digital text is generated, the same shall be translated to Marathi, therefore the source language code for Translation that is to be inserted in Line 18, shall also be hi, which means that language code in Line 7 and Line 18 shall be same. 

For Target Language the code to be inserted in Line 19 shall be mr, i.e., ISO 639 series code for Marathi.  

Understanding of all other parameters remains same as described above in Request Payload for Individual Task.

Pre-Processors and Post-Processors within Compute Request
ASR
Translation
TTS
In Automatic Speech Recognition (ASR) systems, preprocessors and postprocessors play a crucial role in refining the audio input and enhancing the textual output, respectively. Below, we provide details on the available preprocessors and postprocessors, along with an example of how to configure them in your request body.

Preprocessors

Voice Activity Detection (VAD)

Syntax: "preProcessors": ["vad"]

Function: VAD allows audio content longer than 30 seconds to be passed and processed. It helps identify voice activity to ensure that only the detected voice activity is processed, reducing the load and improving the efficiency of the ASR system.

Denoiser

Syntax: "preProcessors": ["denoiser"]

Function: Denoiser helps in improving the accuracy of speech recognition by reducing background noise from audio inputs.

Postprocessors

Hotwords

Syntax: "postProcessors": [{"hotword_list":["पत्रिका"]}]

Function: A hotword is postprocessor allows users to share a list of keyword or phrase in which the system is trained to recognize with higher priority or accuracy. This helps in enhancing the ASR performance. This feature is only applicable for Hindi and for service Id "bhashini/ai4bharat/conformer-multilingual-asr".

       Example:  a Hindi news broadcast where words like "पत्रिका" (Magazine) are frequently mentioned. Adding these as hotwords ensures they are transcribed correctly rather than being replaced by phonetically similar but incorrect words

 Inverse Text Normalization (ITN)

Syntax: "postProcessors": ["itn"]

Function: ITN converts spoken numbers and dates into their written forms. For example, the ASR would output "two thousand and twenty three" as "2023".

Punctuation

Syntax: "postProcessors": ["punctuation"]

Function: This postprocessor adds punctuations to the ASR output, making the text more readable and closer to natural written language.

Example:

ASR Output: "hello how are you"

Punctuation Output: "Hello, how are you?"

The configuration of preprocessors and postprocessors can be included within the config section of the request body as shown below:


Copy
"config": {
    "language": {
        "sourceLanguage": "xx"
    },
    "serviceId": "xxxxx--ssssss-d-ddd--dddd",
    "audioFormat": "flac",
    "samplingRate": 16000,
    "preProcessors": ["vad"],
    "postProcessors": [{
                    "hotword_list": ["पत्रिका", "रंगकर्म", "फिक्र"]
                }, "itn", "punctuation"]
}

Response Payload
This sub-page lets the integrator to actually be able to obtain the inference response with the output of individual tasks or tasks sequence in the order requested by the integrator.

Complete Payload

Copy
{
    "pipelineResponse": [
        {
            "taskType": "asr",
            "config": {
                "serviceId": "ai4bharat/conformer-hi-gpu--t4",
                "language": {
                    "sourceLanguage": "hi",
                    "sourceScriptCode": ""
                },
                "audioFormat": "flac",
                "encoding": null,
                "samplingRate": 16000,
                "postProcessors": null
            },
            "output": [
                {
                    "source": "मेरा नाम महीर है और मैं भाषा यूज़ कर रहा हूँ"
                }
            ],
            "audio": null
        },
        {
            "taskType": "translation",
            "config": null,
            "output": [
                {
                    "source": "मेरा नाम महीर है और मैं भाषा यूज़ कर रहा हूँ",
                    "target": "माझे नाव माहिर आहे आणि मी भाषेच वापरत आहे"
                }
            ],
            "audio": null
        },
        {
            "taskType": "tts",
            "config": {
                "language": {
                    "sourceLanguage": "mr",
                    "sourceScriptCode": ""
                },
                "audioFormat": "wav",
                "encoding": "base64",
                "samplingRate": 22050,
                "postProcessors": null
            },
            "output": null,
            "audio": [
                {
                    "audioContent": "{{returned_base64_content}}",
                    "audioUri": null
                }
            ]
        }
    ]
}
The above JSON Response shows the output of the combination of ASR, Translation and TTS task requested by the integrator in that order. Below we will discuss the individual task response as well as combination of tasks in specific sequence.

Response for Payload sent for Individual Task Request
ASR
Translation
TTS

Copy
{
    "taskType": "asr",
    "config": {
        "serviceId": "xxxxx--ssssss-d-ddd--dddd",
        "language": {
            "sourceLanguage": "hi",
            "sourceScriptCode": ""
        },
        "audioFormat": "flac",
        "encoding": null,
        "samplingRate": 16000,
        "postProcessors": null
    },
    "output": [
        {
            "source": "मेरा नाम महीर है और मैं भाषा यूज़ कर रहा हूँ"
        }
    ],
    "audio": null
}
For individual ASR task request sent by the integrator, the response will contain only one dictionary where taskType will be asr. 

Parameter: config
config parameter returns the configuration details of the output generated.

Parameter: output
output parameter

contains

source parameter which gives the actual digital text of the audio sent as a part of the request as detailed here.

Response for Payload sent for Individual Task Request
ASR+Translation
Translation+TTS
ASR+Translation+TTS
Output of ASR+Translation comes in the form of combination of ASR and Translation dictionary as detailed above.


Copy
{
    "pipelineResponse": [
        {
            "taskType": "asr",
            "config": {
                "serviceId": "xxxxx--ssssss-d-ddd--dddd",
                "language": {
                    "sourceLanguage": "hi",
                    "sourceScriptCode": ""
                },
                "audioFormat": "flac",
                "encoding": null,
                "samplingRate": 16000,
                "postProcessors": null
            },
            "output": [
                {
                    "source": "मेरा नाम महीर है और मैं भाषावर्ष यूज़ कर रहा हूँ"
                }
            ],
            "audio": null
        },
        {
            "taskType": "translation",
            "config": null,
            "output": [
                {
                    "source": "मेरा नाम महीर है और मैं भाषावर्ष यूज़ कर रहा हूँ",
                    "target": "माझे नाव माहिर आहे आणि मी भाषेचे वर्ष वापरत आहे"
                }
            ],
            "audio": null
        }
    ]


Audio Language Detection Compute Call
This page will help the integrator to identify the language spoken in an audio recording. This page will detail out the API call, its parameters, understanding of the Input and Output Payloads.

Endpoint: https://dhruva-api.bhashini.gov.in/services/inference/pipeline

Additional Headers:

Below is the understanding and process of obtaining the additional Headers that shall be sent to make the Pipeline Config API Call. These headers are used for uniquely identifying each integrator for a particular application and authenticate them for the API usage.

Accept: */*

Authorization: INSERT_API_KEY_HERE

Content-Type: application/json

Authorization : it is a HTTP header which is used to authenticate the user and permission of the requester to use protected resources. Authorization key value can be obtained from the My Profile section under the App name -> inference API key value after logging in to Bhashini-Udyat.

Accept : it is a HTTP header which is used to specify the types of content they can process. This helps the server understand what kind of response to send back.

Content-Type : it is HTTP header which is used to indicate the media type of the resource being sent. This helps the user understand how to process the content.

Below is a screenshot from the Postman. Along with standard headers that are sent automatically, Authorization, Accept and Content-Type are the additional parameters sent.

Audio Language Detection Compute Call
Request Payload
This sub-page helps the integrator to understand various different types of request payload based on the individual task or combination of tasks in that sequence that integrator wants to do.

Audio language detection

Copy
{ 
  "pipelineTasks": [ 
      { 
        "taskType": "audio-lang-detection",
        "config": {
                  "serviceId": "{{ald_service_id}}"
                  } 
      }
],
"inputData": {
    "audio": [
        {
            "audioContent": "INSERT_BASE64_AUDIO_HERE"
          //"audioUri": "INSERT_AUDIO_URL_HERE"
        }
    ]
}
}
This request contains 2 major parameters listed below and detailed further down the section:

pipelineTasks

inputData

Parameter: pipelineTasks
Type: Array

This parameter takes an array of tasks, in the form of dictionary of taskType and config, that are to be done by the integrator. 
In the above example, pipelineTasks takes only one dictionary (line 2-9) because integrator wants to do only Audio language detection.

taskType parameter takes String that takes the value audio-lang-detection

config is a single key parameter which maps to another object called serviceId

serviceId
serviceId parameter identifies the specific service/trained model you want to use.

For serviceId as "bhashini/iitmandi/audio-lang-detection/gpu", below are the supported languages-

Assamese

Bengali

English

Hindi

Kannada

Gujarati

Malayalam

Marathi

Odia

Punjabi

Tamil

Telugu

Parameter: inputData
inputData Parameter takes the actual input from the integrator on which the individual task has to be done.  in this case, the input is taken via audioUri or audioContent (base64 format).

either user can pass audioUri as input or audioContent as input.

Previous
Audio Language Detection Compute Call
Next
Response Payload

Audio Language Detection Compute Call
Response Payload
This sub-page lets the integrator to actually be able to obtain the inference response with the output of individual tasks or tasks sequence in the order requested by the integrator.

Complete Payload


Copy
{
    "pipelineResponse": [
        {
            "taskType": "audio-lang-detection",
            "config": null,
            "output": [
                {
                    "audio": {
                        "audioContent": "INPUT_AUDIO_CONTENT",
                        "audioUri": null
                    },
                    "langPrediction": [
                        {
                            "langCode": "LANGUAGE_CODE",
                            "scriptCode": null,
                            "langScore": null
                        }
                    ]
                }
            ],
            "audio": null
        }
    ]
}
The above JSON Response shows the output of the Audio language detection task requested by the integrator in that order. 

Previous
Request Payload
Next
Text Language Detection Compute Call

Text Language Detection Compute Call
This page will help the integrator to identify the language in an input texts. This page will detail out the API call, its parameters, understanding of the Input and Output Payloads.

Endpoint: https://dhruva-api.bhashini.gov.in/services/inference/pipeline

Additional Headers:

Below is the understanding and process of obtaining the additional Headers that shall be sent to make the Pipeline Config API Call. These headers are used for uniquely identifying each integrator for a particular application and authenticate them for the API usage.

Accept: */*

Authorization: INSERT_API_KEY_HERE

Content-Type: application/json

Authorization : it is a HTTP header which is used to authenticate the user and permission of the requester to use protected resources. Authorization key value can be obtained from the My Profile section under the App name -> inference API key value after logging in to Bhashini-Udyat.

Accept : it is a HTTP header which is used to specify the types of content they can process. This helps the server understand what kind of response to send back.

Content-Type : it is HTTP header which is used to indicate the media type of the resource being sent. This helps the user understand how to process the content.

Below is a screenshot from the Postman. Along with standard headers that are sent automatically, Authorization, Accept and Content-Type are the additional parameters sent.

Text Language Detection Compute Call
Request payload
This sub-page helps the integrator to understand various different types of request payload based on the individual task or combination of tasks in that sequence that integrator wants to do.

Text Language Detection payload

Copy
{
    "pipelineTasks": [
        {
            "taskType": "txt-lang-detection",
            "config": {
                "serviceId": "{{tld_service_id}}"
            }
        }
    ],
    "inputData": {
        "input": [
            {
                "source": "INSERT_TEXT_HERE"
            }
        ]
    }
}
This request contains 2 major parameters listed below and detailed further down the section:

pipelineTasks

inputData

Parameter: pipelineTasks
Type: Array

This parameter takes an array of tasks, in the form of dictionary of taskType and config, that are to be done by the integrator. 
In the above example, pipelineTasks takes only one dictionary (line 2-9) because integrator wants to do only text language detection.

taskType parameter takes String that takes the value txt-lang-detection

config is a single key parameter which maps to another object called serviceId.

Service ID
serviceId parameter identifies the specific service/trained model you want to use.

For serviceId as "bhashini/indic-lang-detection-all", below are the supported languages-

• Assamese 

• Bengali 

• Bodo 

• Dogri 

• English 

• Gujarati 

• Hindi 

• Kannada 

• Kashmiri 

• Konkani 

• Maithili 

• Malayalam 

• Manipuri 

• Marathi 

• Nepali 

• Oriya 

• Punjabi 

• Sanskrit 

• Santali 

• Sindhi 

• Tamil 

• Telugu 

• Urdu

For serviceId as "bhashini/iiiith/indic-lang-detection-all", below are the supported languages-

• Assamese 

• Bengali 

• English 

• Gujarati 

• Hindi 

• Kannada 

• Malayalam 

• Manipuri 

• Marathi 

• Oriya 

• Punjabi 

• Tamil 

• Telugu 

• Urdu

Parameter: inputData
inputData Parameter takes the actual input from the integrator on which the individual task has to be done. It can take the input via source parameter .

input text content can be added as a value for source paramater under inputData complex tag

Text Language Detection Compute Call
Response Payload
This sub-page lets the integrator to actually be able to obtain the inference response with the output of individual tasks or tasks sequence in the order requested by the integrator.

Complete payload


Copy
{
    "pipelineResponse": [
        {
            "taskType": "txt-lang-detection",
            "config": null,
            "output": [
                {
                    "source": "INPUT_TEXT",
                    "langPrediction": [
                        {
                            "langCode": "LANGUAGE_CODE",
                            "scriptCode": "SCRIPT_CODE",
                            "langScore": "LANGUAGE_SCORE"
                        }
                    ]
                }
            ],
            "audio": null
        }
    ]
}
The above JSON Response shows the output of the Text language detection task requested by the integrator in that order. 

Speaker Diarization Compute Call
This page will help the integrator to identify the list of speakers spoken in an audio recording. This page will detail out the API call, its parameters, understanding of the Input and Output Payloads

Endpoint: https://dhruva-api.bhashini.gov.in/services/inference/pipeline

Additional Headers:

Below is the understanding and process of obtaining the additional Headers that shall be sent to make the Pipeline Config API Call. These headers are used for uniquely identifying each integrator for a particular application and authenticate them for the API usage.

Accept: */*

Authorization: INSERT_API_KEY_HERE

Content-Type: application/json

Authorization : it is a HTTP header which is used to authenticate the user and permission of the requester to use protected resources. Authorization key value can be obtained from the My Profile section under the App name -> inference API key value after logging in to Bhashini-Udyat.

Accept : it is a HTTP header which is used to specify the types of content they can process. This helps the server understand what kind of response to send back.

Content-Type : it is HTTP header which is used to indicate the media type of the resource being sent. This helps the user understand how to process the content.

Below is a screenshot from the Postman. Along with standard headers that are sent automatically, Authorization, Accept and Content-Type are the additional parameters sent.


Previous
Response Payload
NextSpeaker Diarization Compute Call
This page will help the integrator to identify the list of speakers spoken in an audio recording. This page will detail out the API call, its parameters, understanding of the Input and Output Payloads

Endpoint: https://dhruva-api.bhashini.gov.in/services/inference/pipeline

Additional Headers:

Below is the understanding and process of obtaining the additional Headers that shall be sent to make the Pipeline Config API Call. These headers are used for uniquely identifying each integrator for a particular application and authenticate them for the API usage.

Accept: */*

Authorization: INSERT_API_KEY_HERE

Content-Type: application/json

Authorization : it is a HTTP header which is used to authenticate the user and permission of the requester to use protected resources. Authorization key value can be obtained from the My Profile section under the App name -> inference API key value after logging in to Bhashini-Udyat.

Accept : it is a HTTP header which is used to specify the types of content they can process. This helps the server understand what kind of response to send back.

Content-Type : it is HTTP header which is used to indicate the media type of the resource being sent. This helps the user understand how to process the content.

Below is a screenshot from the Postman. Along with standard headers that are sent automatically, Authorization, Accept and Content-Type are the additional parameters sent.

Overview
The ULCASocketClient is a WebSocket client that enables real-time Speech-to-Text (ASR) processing using BHASHINI's WebSocket API. This allows audio captured from a microphone to be streamed to Bhashini’s ASR service and receive transcription results asynchronously.

Prerequisites
Before you begin, ensure you have:

Access to a microphone

Bhashini API Key and Service ID

Internet connectivity

Java Development Kit (JDK) 8 or higher

Maven project setup

Java libraries:

socket.io-client for WebSocket connection

org.json for JSON processing

Required Dependencies (Maven)

Copy
xmlCopyEdit<dependencies>
    <!-- Socket.IO client -->
    <dependency>
        <groupId>io.socket</groupId>
        <artifactId>socket.io-client</artifactId>
        <version>2.1.0</version>
    </dependency>

    <!-- JSON library -->
    <dependency>
        <groupId>org.json</groupId>
        <artifactId>json</artifactId>
        <version>20220320</version>
    </dependency>
</dependencies>
Key Components
WebSocket Connection: Connect to Bhashini ASR service.

Audio Capture: Access microphone and record audio.

Audio Streaming: Stream audio to the server.

Response Handling: Receive transcription results from the server.

Implementation Steps
1. Initialize Client

Copy
javaCopyEditULCASocketClient client = new ULCASocketClient("YOUR_WEBSOCKET_SERVER_URL", "YOUR_API_KEY");
2. Connect to Server

Copy
javaCopyEditclient.connect();
3. Configure ASR Task

Copy
javaCopyEditJSONObject asrTask = new JSONObject();
asrTask.put("taskType", "asr");

JSONObject asrConfig = new JSONObject();
asrConfig.put("serviceId", "YOUR_SERVICE_ID");

JSONObject asrLanguage = new JSONObject();
asrLanguage.put("sourceLanguage", "en");
asrConfig.put("language", asrLanguage);
asrConfig.put("samplingRate", 8000);
asrConfig.put("audioFormat", "wav");
asrConfig.put("encoding", JSONObject.NULL);

asrTask.put("config", asrConfig);
JSONArray taskSequenceArray = new JSONArray().put(asrTask);
4. Configure Streaming

Copy
javaCopyEditJSONObject streamingConfig = new JSONObject();
streamingConfig.put("responseFrequencyInSecs", 2.0);
streamingConfig.put("responseTaskSequenceDepth", 1);
5. Start Streaming

Copy
javaCopyEditclient.startStream(taskSequenceArray, streamingConfig);
6. Start Audio Streaming (VAD-enabled)
The client listens for the ready event and then starts audio capture:


Copy
javaCopyEditclient.startContinuousAudioStreamingWithVAD();
7. Stop and Disconnect

Copy
javaCopyEditclient.stop(true);
client.disconnect();
 Configuration Parameters
WebSocket Connection
Parameter
Description
serverUrl

WebSocket server URL (wss://dhruva-api.bhashini.gov.in)

apiKey

Your Bhashini API key

ASR Task Configuration
Parameter
Description
taskType

Must be "asr"

serviceId

Specific ASR service ID

sourceLanguage

Language code (e.g., "en")

samplingRate

Usually 8000 Hz

audioFormat

Format: "wav"

encoding

Optional, often null

Streaming Config
Parameter
Description
responseFrequencyInSecs

Frequency of intermediate responses

responseTaskSequenceDepth

Depth of task-level responses

 Audio Specifications
Sampling Rate: 8000 Hz

Bit Depth: 16-bit

Channels: Mono

Encoding: PCM signed

Voice Activity Detection (VAD)
VAD ensures only meaningful (spoken) audio is transmitted:

Captures audio in real-time

Identifies speech segments

Reduces unnecessary data transmission

API Reference
Constructor

Copy
javaCopyEditULCASocketClient(String serverUrl, String apiKey)
Methods
Method
Description
connect()

Establish WebSocket connection

startStream(...)

Begin audio streaming

stop(boolean)

Stop the stream

disconnect()

Disconnect from server

startContinuousAudioStreamingWithVAD()

Start mic with VAD

convertByteToInt16(byte[])

Convert byte array to 16-bit short array

toUnsignedBytes(short[])

Convert short array to unsigned bytes

WebSocket Events
Event
Trigger
connect

Connection successful

disconnect

Disconnected

ready

Server is ready to receive

response

ASR result received

message

General server message

abort

Server aborted task

terminate

Server terminated connection

 Complete Example

Copy
javaCopyEditpublic static void main(String[] args) {
    try {
        ULCASocketClient client = new ULCASocketClient("YOUR_WS_URL", "YOUR_API_KEY");
        client.connect();

        // ASR task config
        JSONObject asrTask = new JSONObject();
        asrTask.put("taskType", "asr");

        JSONObject config = new JSONObject();
        config.put("serviceId", "YOUR_SERVICE_ID");
        config.put("language", new JSONObject().put("sourceLanguage", "en"));
        config.put("samplingRate", 8000);
        config.put("audioFormat", "wav");
        config.put("encoding", JSONObject.NULL);
        asrTask.put("config", config);

        JSONArray taskSequence = new JSONArray().put(asrTask);

        // Streaming config
        JSONObject streamConfig = new JSONObject();
        streamConfig.put("responseFrequencyInSecs", 2.0);
        streamConfig.put("responseTaskSequenceDepth", 1);

        client.startStream(taskSequence, streamConfig);

        System.out.println("Streaming started. Press Enter to stop...");
        System.in.read();

        client.stop(true);
        client.disconnect();

    } catch (Exception e) {
        e.printStackTrace();
    }
}
 Troubleshooting
 Connection Issues
Check serverUrl

Validate your API key

Ensure internet access

 No ASR Output
Confirm serviceId

Check audio format (wav, 8000 Hz)

Speak clearly/loud enough for VAD

Debugging Tips
Use console logs

Add System.out.println in event handlers

Watch server response events for error codesAppendix
Full Forms
ULCA: Universal Language Contribution APIs

ASR: Automatic Speech Recognition

NMT: Neural Machine Translation

TTS: Text to Speech